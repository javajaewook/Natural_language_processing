{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 데이터 크롤링 (2013 년 ~ 2015년)\n",
    "\n",
    "크롤링한 웹 사이트 : [멜론](https://www.melon.com/), [가온차트](http://gaonchart.co.kr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "sys.setrecursionlimit(10000000)\n",
    "driver = webdriver.Chrome('../chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'아이돌목록.xlsx'와, 멜론을 참고하여, 그룹명, id, 남/녀, 소속사 정보를 미리 리스트로 만듦 (id는, 멜론에서, 아티스트를 특정할수 있는 파리미터로 사용됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [\n",
    "['인피니트 에이치' ,'715422' ,'남', '울림 엔터테인먼트'],\n",
    "['제아 파이브', '719888', '남', '스타제국'],\n",
    "['히스토리', '721703', '남', '로엔 엔터테인먼트'],\n",
    "['엘씨나인', '723216', '남', '내가네트워크'],\n",
    "['핫젝갓알지', '722812', '남', ''],\n",
    "['스피드', '714785', '남', 'MBK 엔터테인먼트'],\n",
    "['방탄소년단', '672375', '남', '빅히트 엔터테인먼트'],\n",
    "['소년공화국', '724751', '남', '유니버설 뮤직. 해피트라이브 엔터테인먼트'],\n",
    "['엠파이어', '729613', '남', 'CMG초록별'],\n",
    "['엔오엠', '733672', '남', '제이엠스타 엔터테인먼트'],\n",
    "['제노티', '741698', '남', '후너스 엔터테인먼트'],\n",
    "['프로씨', '745722', '남', '지앤아이 엔터테인먼트'],\n",
    "['투윤', '715898', '여', '큐브 엔터테인먼트'],\n",
    "['다소니 (솔지하니)', '717917', '여', '바나나컬쳐 엔터테인먼트'],\n",
    "['레이디스 코드', '718807', '여', '일광폴라리스 엔터테인먼트'],\n",
    "['투아이즈', '724183', '여', 'iHQ'],\n",
    "['베스티', '727818', '여', 'YNB 엔터테인먼트'],\n",
    "['AOA 블랙', '', '여', 'FNC 엔터테인먼트'],\n",
    "['와썹', '729885', '여', '마피아 레코드'],\n",
    "['키스&크라이', '741841', '여', '위닝인사이트엠'],\n",
    "['틴트', '742722', '여', 'GH 엔터테인먼트'],\n",
    "['엠앤엔', '744134', '여', '미스틱 엔터테인먼트'],\n",
    "['풍뎅이','747339', '여', 'DoMA 엔터테인먼트'],\n",
    "['비트윈', '749361', '남', '골드문 뮤직, 에렌 엔터테인먼트'],\n",
    "['비에이', '749603', '남', '크롬 엔터테인먼트'],\n",
    "['갓세븐', '751059', '남', 'JYP 엔터테인먼트'],\n",
    "['투하트', '760193', '남', 'SM 엔터테인먼트. 울림 엔터테인먼트'],\n",
    "['제이제이씨씨', '762950', '남', '더 잭키 찬 그룹 코리아'],\n",
    "['하이포', '767374', '남', 'N.A.P. 엔터테인먼트'],\n",
    "['빅플로', '775702', '남', '에이치오컴퍼니'],\n",
    "['헤일로', '775874', '남', '아인홀딩스'], ### skip\n",
    "['엘에이유', '1383117', '남', '팬 엔터테인먼트'],\n",
    "['비아이지', '777394', '남', 'GH 엔터테인먼트'],\n",
    "['위너', '775197', '남', 'YG 엔터테인먼트'],\n",
    "['유니크', '786696', '남', '위에화 엔터테인먼트'],\n",
    "['매드타운', '786412', '남', '지앤아이 엔터테인먼트'],\n",
    "['핫샷', '787976', '남', '케이오사운드/아더앤에이블/스타크루이엔티'],\n",
    "['지디 앤 태양', '790881', '남', 'YG 엔터테인먼트'],\n",
    "['인피니트F', '789608', '남', '울림 엔터테인먼트'],\n",
    "['칠학년일반', '753271', '여', '다른별 엔터테인먼트'],\n",
    "['윙스', '760801', '여', '소니뮤직'],\n",
    "['레드벨벳', '780066', '여', 'SM 엔터테인먼트'],\n",
    "['스피카.S', '785143', '여', 'CJ E&M, B2M 엔터테인먼트'],\n",
    "['레인보우 블랙', '750398', '여', 'DSP 미디어'],\n",
    "['베리굿', '773603', '여', '아시아브릿지 엔터테인먼트'],\n",
    "['단발머리', '774914', '여', '크롬 엔터테인먼트'],\n",
    "['마마무', '750053', '여', 'RBW'],\n",
    "['에이코어', '778135', '여', '두리퍼블릭 엔터테인먼트'],\n",
    "['라붐', '783462', '여', 'NH 미디어. 내가네트워크'],\n",
    "['(밍스)드림캐쳐', '785548', '여', '해피페이스 엔터테인먼트'],\n",
    "['딸기우유', '787080', '여', '크롬엔터테인먼트'],\n",
    "['러블리즈', '789331', '여', '울림 엔터테인먼트'],\n",
    "['워너비', '790377', '여', '제니스 미디어 콘텐츠'],\n",
    "['소나무', '792822', '여', 'TS 엔터테인먼트'],\n",
    "['블락비 바스타즈', '858846', '남', '세븐시즌스'],\n",
    "['로미오', '860516', '남', 'CT 엔터테인먼트'],\n",
    "['몬스타엑스', '791216', '남', '스타쉽 엔터테인먼트'],\n",
    "['엔플라잉', '861430', '남', 'FNC 엔터테인먼트'],\n",
    "['세븐틴', '861436', '남', '플레디스 엔터테인먼트'],\n",
    "['아이콘', '895741', '남', 'YG 엔터테인먼트'],\n",
    "['데이식스', '894864', '남', 'JYP 엔터테인먼트'],\n",
    "['포켓걸스', '858582', '여', '미스디카'],\n",
    "['업텐션', '894825', '남', '티오피 미디어'],\n",
    "['브이에이브이', '906245', '남', '에이팀'],\n",
    "['맵식스', '913347', '남', '드림티 엔터테인먼트'],\n",
    "['스누퍼', '856374', '남', '위드메이'],\n",
    "['여자친구', '828478', '여', '쏘스 뮤직'],\n",
    "['러버소울', '837535', '여', '해피트라이브 엔터테인먼트. 위드에이치씨'],\n",
    "['씨엘씨', '839579', '여', '큐브 엔터테인먼트'],\n",
    "['빅스LR', '882304', '남', '젤리피쉬 엔터테인먼트'],\n",
    "['오마이걸', '857994', '여', 'WM 엔터테인먼트'],\n",
    "['멜로디데이', '693951', '여', '로엔 엔터테인먼트, 뷰가 엔터테인먼트'],\n",
    "['에이프릴', '882818', '여', 'DSP 미디어'],\n",
    "['다이아', '890286', '여', 'MBK 엔터테인먼트'],\n",
    "['트와이스', '905701', '여', 'JYP 엔터테인먼트']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list를 받아서 tsv파일로 저장하는 함수 정의\n",
    "\n",
    "원래 모든 아티스트를 모두 크롤링 한 후에 한번에 tsv 파일로 만드려 했으나, 컴퓨터 메모리 문제로 인하여 아티스트마다 tsv 파일을 만들었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tsv(date, artist, title, mf, genere, rank, writer, producer, company, lyrics, filename = 'result.tsv'):\n",
    "    f= open(filename, 'w', encoding='utf-8')\n",
    "    for i in range(0, len(date)):\n",
    "        if (lyrics[i] == ''):\n",
    "            continue\n",
    "        f.write(''.join(date[i].split('.')) + '\\t' + ','.join(artist[i]) + '\\t' + title[i] + '\\t' + mf[i] + '\\t' + genere[i] + '\\t' + rank[i] + '\\t' + ','.join(writer[i]) + '\\t' + ','.join(producer[i]) + '\\t' + company[i] + '\\t' + lyrics[i].strip() + '\\n')\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "driver.get('https://www.melon.com/artist/song.htm?artistId='+lists[0][1])\n",
    "try:\n",
    "    element = WebDriverWait(driver, 3).until(\n",
    "        EC.presence_of_element_located((By.ID, \"myDynamicElement\"))\n",
    "    )\n",
    "except:\n",
    "    print()\n",
    "\n",
    "# # 팝업 끄기\n",
    "# close = driver.find_element(By.XPATH, \"(//a[@class='btn_close'])[last()]\")\n",
    "# close.send_keys('\\n')\n",
    "\n",
    "\n",
    "# more = driver.find_element(By.XPATH, \"(//div[@class='btn_more_list']/a)\")\n",
    "# driver.execute_script(\"arguments[0].click();\", more)\n",
    "\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# tag = soup.find_all('tbody')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for li in lists:\n",
    "    if (li[1] == ''):\n",
    "        continue\n",
    "    \n",
    "    date = []\n",
    "    title = []\n",
    "    artist = []\n",
    "    mf = []\n",
    "    genere = []\n",
    "    rank = []\n",
    "    writer = []\n",
    "    producer = []\n",
    "    company = []\n",
    "    lyrics = []\n",
    "    ranking_per_artists = []\n",
    "    \n",
    "    \n",
    "    albums = []\n",
    "\n",
    "    ## 앨범 모으기\n",
    "    pages = 1\n",
    "    if (soup.find('span', {'class':'page_num'}).a != None):\n",
    "        pages = int(soup.find('span', {'class':'page_num'}).find_all('a')[-1].string)\n",
    "    for page in range(pages):\n",
    "        driver.get('https://www.melon.com/artist/album.htm?artistId='+li[1]+'#params%5BlistType%5D=0&params%5BorderBy%5D=ISSUE_DATE&params%5BartistId%5D='+li[1]+'&po=pageObj&startIndex='+str(page*15))\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        for album in soup.find_all('li', {'class':'album11_li'}):\n",
    "            if (str(album.dd.div.span.string) != 'Various Artists'):\n",
    "                albums.append(str(album.dt.a.string))\n",
    "            #print(str(album.find_all('a')[2].string))\n",
    "\n",
    "\n",
    "    ## 앨범 모으기 끝, 앨범속 곡 순위 모으기\n",
    "    ranking = {}\n",
    "    for album in albums:\n",
    "        album = album.split('(')[0]\n",
    "        for years in range(2013, 2020 + 1):\n",
    "\n",
    "            driver.get('http://gaonchart.co.kr/main/section/search/list.gaon?serviceGbn=ALL&nationGbn=T&yyyy='+str(years)+'&condition=3&search_str='+album)\n",
    "            try:\n",
    "                element = WebDriverWait(driver, 2.5).until(\n",
    "                    EC.presence_of_element_located((By.ID, \"myDynamicElement\"))\n",
    "                )\n",
    "            except:\n",
    "                print( \"\", end='')\n",
    "\n",
    "            for _ in range(3):\n",
    "                try:\n",
    "                    more = driver.find_element(By.XPATH, \"(//div[@id='divMore_ALL_week'])\")\n",
    "                    driver.execute_script(\"arguments[0].click();\", more)\n",
    "                except:    # 예외가 발생했을 때 실행됨\n",
    "                    try:\n",
    "                        element = WebDriverWait(driver, 1).until(\n",
    "                            EC.presence_of_element_located((By.ID, \"myDynamicElement\"))\n",
    "                        )\n",
    "                    except:\n",
    "                        print( \"\", end='')\n",
    "\n",
    "                    break\n",
    "\n",
    "            try:\n",
    "                html = driver.page_source\n",
    "            except:\n",
    "                html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            soup.find('table', {'id':'chart_ALL_week'}).find_all('tr')[1:]\n",
    "\n",
    "            for item in soup.find('table', {'id':'chart_ALL_week'}).find_all('tr')[1:]:\n",
    "                if (ranking.get(str(item.find_all('td')[2].string)) == None):\n",
    "                    ranking[str(item.find_all('td')[2].string)] = int(item.find_all('td')[1].string)\n",
    "                elif(ranking[str(item.find_all('td')[2].string)] > int(item.find_all('td')[1].string)): \n",
    "                    ranking[str(item.find_all('td')[2].string)] = int(item.find_all('td')[1].string)\n",
    "    ranking_per_artists.append(ranking)\n",
    "    ## 앨범속 곡 순위 모으기 끝\n",
    "\n",
    "    \n",
    "    \n",
    "    driver.get('https://www.melon.com/artist/song.htm?artistId='+li[1] + '#params%5BlistType%5D=A&params%5BorderBy%5D=ISSUE_DATE&params%5BartistId%5D='+li[1]+'&po=pageObj&startIndex=0')\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    \n",
    "    \n",
    "    page = 1\n",
    "    if (soup.find('span', {'class':'page_num'}).a != None):\n",
    "        page = int(soup.find('span', {'class':'page_num'}).find_all('a')[-1].string)\n",
    "\n",
    "    for pg in range(page):\n",
    "\n",
    "        driver.get('https://www.melon.com/artist/song.htm?artistId='+li[1] + '#params%5BlistType%5D=A&params%5BorderBy%5D=ISSUE_DATE&params%5BartistId%5D='+li[1]+'&po=pageObj&startIndex=' + str(pg*50))\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        elem = driver.find_elements(By.XPATH, \"(//a[@class='btn btn_icon_detail'])\")\n",
    "        i = 0\n",
    "        for it in range(len(elem)):\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            tit = str(soup.find_all('tr')[1:][it].find_all('span')[2].string)\n",
    "    \n",
    "    \n",
    "            # 제목\n",
    "            title.append(tit)\n",
    "\n",
    "            elem = driver.find_elements(By.XPATH, \"(//a[@class='btn btn_icon_detail'])\")\n",
    "            elem[i].send_keys('\\n')\n",
    "            time.sleep(1)\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            # 날짜\n",
    "            dat = soup.find('div', {'class':'meta'}).find_all('dd')[1].string\n",
    "            date.append(str(dat))\n",
    "\n",
    "            # 가수\n",
    "            art = []\n",
    "            for ar in soup.find('div', {'class':'artist'}).find_all('a', {'class':'artist_name'}):\n",
    "                art.append(str(ar.span.string))\n",
    "            artist.append(art)\n",
    "            # 남녀\n",
    "            mf.append(li[2])\n",
    "\n",
    "            # 장르\n",
    "            gen = soup.find('div', {'class':'meta'}).find_all('dd')[2].string\n",
    "            genere.append(str(gen))\n",
    "            # 최고순위\n",
    "            if(ranking.get(tit) == None):\n",
    "                rank.append('-')\n",
    "            else:\n",
    "                rank.append(str(ranking.get(tit)))\n",
    "\n",
    "\n",
    "            if (soup.find('div', {'class':'section_prdcr'}) != None):\n",
    "                ar = soup.find('div', {'class':'section_prdcr'}).find_all('a', {'class':'artist_name'})\n",
    "                ty = soup.find('div', {'class':'section_prdcr'}).find_all('span', {'class':'type'})\n",
    "                pr = []\n",
    "                wr = []\n",
    "                for ak, t in zip(ar, ty):\n",
    "                    if (t.string == '작사'): ## 작사가 일 경우\n",
    "                        wr.append(ak.string)\n",
    "                    else: ## 작곡가 일 경우\n",
    "                        pr.append(ak.string)\n",
    "            writer.append(wr)\n",
    "            producer.append(pr)\n",
    "            # 소속사\n",
    "            company.append(li[3])\n",
    "\n",
    "            # 가사\n",
    "            st = ''\n",
    "            if (soup.find('div', {'class':'lyric'}) != None):\n",
    "                for a in soup.find('div', {'class':'lyric'}):\n",
    "                    if (a != soup.find('div', {'class':'lyric'}).next):\n",
    "                        st += str(a) + ' '\n",
    "                st = st.strip()\n",
    "            lyrics.append(st)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            driver.back()\n",
    "            time.sleep(1)\n",
    "\n",
    "            i+=1\n",
    "            \n",
    "    ## 한 가수에 대해서\n",
    "    save_tsv(date, artist, title, mf, genere, rank, writer, producer, company, lyrics, filename = './result/'+li[0]+'.tsv')\n",
    "    \n",
    "    \n",
    "    # 혹시나 해서 크롤링 한 list 데이터도 pickle 로 저장함\n",
    "    try:\n",
    "        os.mkdir('./data/'+li[0])\n",
    "    except:\n",
    "        print( \"\", end='')\n",
    "        \n",
    "    with open('./data/'+li[0]+'/date.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(date, aaaa)\n",
    "    \n",
    "    with open('./data/'+li[0]+'/title.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(title, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/artist.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(artist, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/mf.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(mf, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/genere.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(genere, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/rank.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(rank, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/writer.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(writer, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/producer.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(producer, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/company.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(company, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/lyrics.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(lyrics, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/ranking_per_artists.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(ranking_per_artists, aaaa)\n",
    "        \n",
    "    with open('./data/'+li[0]+'/albums.pkl', 'wb') as aaaa:\n",
    "        pickle.dump(albums, aaaa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
